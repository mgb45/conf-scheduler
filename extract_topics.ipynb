{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import lda\n",
    "import textmining\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load destemming data\n",
    "destem = {}\n",
    "with open(\"stopwords/destemming.txt\") as f:\n",
    "        for entry in f:\n",
    "                entry = entry.split(':')\n",
    "                if len(entry) == 2:\n",
    "                        destem[entry[0].strip()] = entry[1].strip()\n",
    "\n",
    "esc_chars = ''.join(c for c in map(chr, range(33,256)) if not c.isalnum())+'0123456789'\n",
    "\n",
    "# Remove stop words\n",
    "stopwords = ''\n",
    "for i in range(1,8):\n",
    "    stop_file = \"stopwords/stop-words_english_%d_en.txt\" % i\n",
    "    with open(stop_file) as myfile:\n",
    "        stopwords += ' ' + myfile.read()\n",
    "\n",
    "stopwords = stopwords.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create termdocument matrix\n",
    "tdm = textmining.TermDocumentMatrix()\n",
    "# Load document\n",
    "\n",
    "path_name = './text/'\n",
    "pid_list = []\n",
    "for fname in os.listdir(path_name):\n",
    "    #print 'Processing ' + fname\n",
    "    \n",
    "    with open(os.path.join(path_name,fname)) as myfile:\n",
    "\n",
    "        data = myfile.read().replace('\\n', ' ')  \n",
    "\n",
    "        for ch in esc_chars:\n",
    "            data = data.replace(ch, '')  \n",
    "\n",
    "        data = data.lower()\n",
    "\n",
    "        word_list = data.split()\n",
    "        data =  ' '.join([i for i in word_list if len(i) > 3 and i not in stopwords])\n",
    "\n",
    "        # Do destemming\n",
    "        for k, v in destem.iteritems():\n",
    "            data = data.replace(k, v)\n",
    "\n",
    "\n",
    "        tdm.add_doc(data)\n",
    "        pid_list.append(fname[0:4])\n",
    "\n",
    "temp = list(tdm.rows(cutoff=1))\n",
    "# Extract words\n",
    "vocab = tuple(temp[0])\n",
    "# Extract word freqs\n",
    "X = np.array(temp[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fit lda model - used to select area chairs\n",
    "model = lda.LDA(n_topics=9, n_iter=25000, alpha=0.1, eta=0.01, random_state=1)\n",
    "model.fit(X) \n",
    "\n",
    "topic_word = model.topic_word_\n",
    "doc_topic = model.doc_topic_\n",
    "\n",
    "# Show topics\n",
    "n_top_words = 8\n",
    "for i, topic_dist in enumerate(topic_word):\n",
    "    topic_words = np.array(vocab)[np.argsort(topic_dist)][:-n_top_words:-1]\n",
    "    print('Topic {}: {}'.format(i, ' '.join(topic_words)))\n",
    "\n",
    "np.savetxt(\"topic_word.csv\", topic_word, delimiter=\",\")\n",
    "np.savetxt(\"doc_topic.csv\", doc_topic, delimiter=\",\")\n",
    "np.savetxt(\"vocab.csv\",np.array(vocab),delimiter=\",\", fmt=\"%s\")\n",
    "np.savetxt(\"filelist.csv\",np.array(pid_list),delimiter=\",\", fmt=\"%s\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
